{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Functions"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-05-04T16:59:51.187119Z","iopub.status.busy":"2023-05-04T16:59:51.186533Z","iopub.status.idle":"2023-05-04T17:00:20.813770Z","shell.execute_reply":"2023-05-04T17:00:20.812526Z","shell.execute_reply.started":"2023-05-04T16:59:51.187081Z"},"scrolled":true,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting stable-baselines3[extra]\n","  Downloading stable_baselines3-1.8.0-py3-none-any.whl (174 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.5/174.5 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (1.3.5)\n","Requirement already satisfied: typing-extensions<5,>=4.0 in /opt/conda/lib/python3.7/site-packages (from stable-baselines3[extra]) (4.4.0)\n","Requirement already satisfied: torch>=1.11 in /opt/conda/lib/python3.7/site-packages (from stable-baselines3[extra]) (1.13.0)\n","Requirement already satisfied: cloudpickle in /opt/conda/lib/python3.7/site-packages (from stable-baselines3[extra]) (2.2.1)\n","Collecting gym==0.21\n","  Downloading gym-0.21.0.tar.gz (1.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from stable-baselines3[extra]) (1.21.6)\n","Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from stable-baselines3[extra]) (3.5.3)\n","Collecting importlib-metadata~=4.13\n","  Downloading importlib_metadata-4.13.0-py3-none-any.whl (23 kB)\n","Requirement already satisfied: opencv-python in /opt/conda/lib/python3.7/site-packages (from stable-baselines3[extra]) (4.5.4.60)\n","Collecting autorom[accept-rom-license]~=0.6.0\n","  Downloading AutoROM-0.6.1-py3-none-any.whl (9.4 kB)\n","Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from stable-baselines3[extra]) (4.64.1)\n","Requirement already satisfied: rich in /opt/conda/lib/python3.7/site-packages (from stable-baselines3[extra]) (13.2.0)\n","Requirement already satisfied: tensorboard>=2.9.1 in /opt/conda/lib/python3.7/site-packages (from stable-baselines3[extra]) (2.11.2)\n","Requirement already satisfied: pillow in /opt/conda/lib/python3.7/site-packages (from stable-baselines3[extra]) (9.4.0)\n","Collecting ale-py==0.7.4\n","  Downloading ale_py-0.7.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: psutil in /opt/conda/lib/python3.7/site-packages (from stable-baselines3[extra]) (5.9.3)\n","Requirement already satisfied: importlib-resources in /opt/conda/lib/python3.7/site-packages (from ale-py==0.7.4->stable-baselines3[extra]) (5.10.2)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas) (2023.2)\n","Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from autorom[accept-rom-license]~=0.6.0->stable-baselines3[extra]) (8.1.3)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from autorom[accept-rom-license]~=0.6.0->stable-baselines3[extra]) (2.28.2)\n","Collecting AutoROM.accept-rom-license\n","  Downloading AutoROM.accept-rom-license-0.6.1.tar.gz (434 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.7/434.7 kB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n","\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n","\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata~=4.13->stable-baselines3[extra]) (3.11.0)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (59.8.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.6.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.8.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (2.2.3)\n","Requirement already satisfied: protobuf<4,>=3.9.2 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.20.3)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.4.6)\n","Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.4.0)\n","Requirement already satisfied: grpcio>=1.24.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.51.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.35.0)\n","Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.38.4)\n","Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.4.1)\n","Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->stable-baselines3[extra]) (0.11.0)\n","Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->stable-baselines3[extra]) (3.0.9)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->stable-baselines3[extra]) (23.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->stable-baselines3[extra]) (1.4.4)\n","Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->stable-baselines3[extra]) (4.38.0)\n","Requirement already satisfied: markdown-it-py<3.0.0,>=2.1.0 in /opt/conda/lib/python3.7/site-packages (from rich->stable-baselines3[extra]) (2.1.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /opt/conda/lib/python3.7/site-packages (from rich->stable-baselines3[extra]) (2.14.0)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (4.2.4)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->stable-baselines3[extra]) (1.3.1)\n","Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.7/site-packages (from markdown-it-py<3.0.0,>=2.1.0->rich->stable-baselines3[extra]) (0.1.2)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->autorom[accept-rom-license]~=0.6.0->stable-baselines3[extra]) (2022.12.7)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->autorom[accept-rom-license]~=0.6.0->stable-baselines3[extra]) (2.1.1)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->autorom[accept-rom-license]~=0.6.0->stable-baselines3[extra]) (3.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->autorom[accept-rom-license]~=0.6.0->stable-baselines3[extra]) (1.26.14)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.7/site-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]) (2.1.1)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->stable-baselines3[extra]) (3.2.2)\n","Building wheels for collected packages: gym, AutoROM.accept-rom-license\n","  Building wheel for gym (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for gym: filename=gym-0.21.0-py3-none-any.whl size=1616823 sha256=427c44215271d562863a75e59e41cc294b5449b557d3049afca9ec6175b6d8cc\n","  Stored in directory: /root/.cache/pip/wheels/d3/78/02/af51e23f21c31c0167d288296d764a22abb842ac6e8f52ebfa\n","  Building wheel for AutoROM.accept-rom-license (pyproject.toml) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.6.1-py3-none-any.whl size=446660 sha256=41df6159b1ff3cae247e3b34963f4e670e141bf2c3caf9d5fca955f717f04de2\n","  Stored in directory: /root/.cache/pip/wheels/f2/56/c8/15764130eda5e4d3b867b7c86b70846aa56dde22083cf34a5f\n","Successfully built gym AutoROM.accept-rom-license\n","Installing collected packages: importlib-metadata, gym, ale-py, stable-baselines3, AutoROM.accept-rom-license, autorom\n","  Attempting uninstall: importlib-metadata\n","    Found existing installation: importlib-metadata 4.11.4\n","    Uninstalling importlib-metadata-4.11.4:\n","      Successfully uninstalled importlib-metadata-4.11.4\n","  Attempting uninstall: gym\n","    Found existing installation: gym 0.23.1\n","    Uninstalling gym-0.23.1:\n","      Successfully uninstalled gym-0.23.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cudf 21.12.2 requires cupy-cuda115, which is not installed.\n","librosa 0.10.0.post2 requires soundfile>=0.12.1, but you have soundfile 0.11.0 which is incompatible.\n","flake8 5.0.4 requires importlib-metadata<4.3,>=1.1.0; python_version < \"3.8\", but you have importlib-metadata 4.13.0 which is incompatible.\n","cmudict 1.0.13 requires importlib-metadata<6.0.0,>=5.1.0, but you have importlib-metadata 4.13.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed AutoROM.accept-rom-license-0.6.1 ale-py-0.7.4 autorom-0.6.1 gym-0.21.0 importlib-metadata-4.13.0 stable-baselines3-1.8.0\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["! pip install stable-baselines3[extra] pandas "]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-05-04T17:00:21.775503Z","iopub.status.busy":"2023-05-04T17:00:21.775102Z","iopub.status.idle":"2023-05-04T17:00:24.875330Z","shell.execute_reply":"2023-05-04T17:00:24.874297Z","shell.execute_reply.started":"2023-05-04T17:00:21.775462Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import torch as th\n","import pandas as pd\n","from stable_baselines3 import PPO"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-05-04T17:00:24.877225Z","iopub.status.busy":"2023-05-04T17:00:24.876628Z","iopub.status.idle":"2023-05-04T17:00:24.883334Z","shell.execute_reply":"2023-05-04T17:00:24.881552Z","shell.execute_reply.started":"2023-05-04T17:00:24.877168Z"},"trusted":true},"outputs":[],"source":["datasets_dict = {}\n","datasets_dict['MDDR'] = dict(fullname='MDDR',partition=['DS1','DS2','DS3'])\n","# datasets_dict['DUD'] = dict(fullname='DUD')\n","# datasets_dict['MUV'] = dict(fullname='MUV')"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-05-04T17:00:24.885838Z","iopub.status.busy":"2023-05-04T17:00:24.884770Z","iopub.status.idle":"2023-05-04T17:00:24.893185Z","shell.execute_reply":"2023-05-04T17:00:24.892047Z","shell.execute_reply.started":"2023-05-04T17:00:24.885801Z"},"trusted":true},"outputs":[],"source":["def jaccard_similarity(fp1, fp2):\n","    return np.dot(fp1, fp2) / (np.sum(fp1**2) + np.sum(fp2**2) - np.dot(fp1, fp2))\n"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-05-04T17:00:24.895586Z","iopub.status.busy":"2023-05-04T17:00:24.894544Z","iopub.status.idle":"2023-05-04T17:00:24.904594Z","shell.execute_reply":"2023-05-04T17:00:24.903616Z","shell.execute_reply.started":"2023-05-04T17:00:24.895549Z"},"trusted":true},"outputs":[],"source":["def cosine_similarity(a, b):\n","    dot_product = np.dot(a, b)\n","    norm_a = np.linalg.norm(a)\n","    norm_b = np.linalg.norm(b)\n","    return dot_product / (norm_a * norm_b)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-05-04T17:00:24.906637Z","iopub.status.busy":"2023-05-04T17:00:24.906062Z","iopub.status.idle":"2023-05-04T17:00:25.137883Z","shell.execute_reply":"2023-05-04T17:00:25.136840Z","shell.execute_reply.started":"2023-05-04T17:00:24.906599Z"},"trusted":true},"outputs":[],"source":["from scipy.stats import spearmanr\n","def spearman_correlation(x, y):\n","    correlation, p_value = spearmanr(x, y)\n","    return correlation"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-05-04T17:00:25.139898Z","iopub.status.busy":"2023-05-04T17:00:25.139440Z","iopub.status.idle":"2023-05-04T17:00:25.145931Z","shell.execute_reply":"2023-05-04T17:00:25.144897Z","shell.execute_reply.started":"2023-05-04T17:00:25.139859Z"},"trusted":true},"outputs":[],"source":["def pearson_correlation(x, y):\n","    covariance = np.cov(x, y)[0][1]\n","    std_x = np.std(x)\n","    std_y = np.std(y)\n","    return covariance / (std_x * std_y)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-05-04T17:00:25.148582Z","iopub.status.busy":"2023-05-04T17:00:25.147803Z","iopub.status.idle":"2023-05-04T17:00:25.155422Z","shell.execute_reply":"2023-05-04T17:00:25.154179Z","shell.execute_reply.started":"2023-05-04T17:00:25.148543Z"},"trusted":true},"outputs":[],"source":["def euclidean_distance(x, y):\n","    return np.sqrt(np.sum((x - y)**2))"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-05-04T17:00:25.157712Z","iopub.status.busy":"2023-05-04T17:00:25.157054Z","iopub.status.idle":"2023-05-04T17:00:25.164744Z","shell.execute_reply":"2023-05-04T17:00:25.163539Z","shell.execute_reply.started":"2023-05-04T17:00:25.157675Z"},"trusted":true},"outputs":[],"source":["similarities = {}\n","similarities[\"cosine\"] = lambda fp1,fp2 : cosine_similarity(fp1,fp2)\n","similarities[\"euclidean\"] = lambda fp1,fp2 : euclidean_distance(fp1,fp2)\n","similarities[\"spearman\"] = lambda fp1,fp2 : spearman_correlation(fp1,fp2)\n","similarities[\"pearson\"] = lambda fp1,fp2 : pearson_correlation(fp1,fp2)\n"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-05-04T17:00:25.170432Z","iopub.status.busy":"2023-05-04T17:00:25.170161Z","iopub.status.idle":"2023-05-04T17:00:25.178182Z","shell.execute_reply":"2023-05-04T17:00:25.177053Z","shell.execute_reply.started":"2023-05-04T17:00:25.170407Z"},"trusted":true},"outputs":[],"source":["# y = np.random.random((1024))*100\n","x = np.array([0,2,4,61.10,6.2,7.3,6,5])\n","y = np.array([0,0,4,6,6,0,1,100])"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-05-04T17:00:25.180790Z","iopub.status.busy":"2023-05-04T17:00:25.180124Z","iopub.status.idle":"2023-05-04T17:00:25.194606Z","shell.execute_reply":"2023-05-04T17:00:25.193517Z","shell.execute_reply.started":"2023-05-04T17:00:25.180751Z"},"trusted":true},"outputs":[],"source":["def loadDataset(name,fp,partition=False):\n","    classes=[]\n","    classes_count=[]\n","    classes_df={}\n","    descrpitors=[]\n","\n","    dataset_path = \"\"\n","    if name in datasets_dict.keys():\n","        if partition:\n","            if \"partition\" in datasets_dict[name].keys():\n","                if partition in datasets_dict[name][\"partition\"]:\n","                    dataset_path = \"./Datasets/\"+name+\"/\"+partition\n","                else: \n","                    print(\"Partition doesn't exist\")    \n","            else:\n","                print(\"This dataset doesn't have a partition\")\n","\n","        else:\n","            if \"partition\" in datasets_dict[name].keys():\n","                print(datasets_dict[name][\"partition\"])\n","                print(\"Enter the partition name\")\n","            else:\n","                dataset_path = \"./Datasets/\"+name\n","        \n","        if dataset_path != \"\":\n","            with open(dataset_path+\"/ActivityClass.txt\", 'r') as file:\n","                i=0\n","                file.readline()\n","                for line in file:\n","                    l = line.split()\n","                    classes+=[i]*int(l[2])\n","                    classes_count.append(int(l[2]))\n","                    i+=1\n","\n","            with open(dataset_path+\"/ActivityDecoyClass.txt\", 'r') as file:\n","                i=-1\n","                file.readline()\n","                for line in file:\n","                    l = line.split()\n","                    classes+=[i]*int(l[2])\n","                    i-=1\n","                    \n","            with open(dataset_path+\"/FP/\"+fp+\".txt\", 'r') as file:\n","                i=0\n","                for line in file:\n","                    descrpitors.append(np.array(line.split(),dtype=np.int8))\n","                    \n","                    classes_df[i+1] = {\"id\":i,\"class\":classes[i]}\n","                    i+=1\n","    else:\n","        print(\"Dataset doesn't existe\")\n","    \n","    return np.array(descrpitors),pd.DataFrame(classes_df).T,classes_count"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-05-04T17:00:25.197044Z","iopub.status.busy":"2023-05-04T17:00:25.196307Z","iopub.status.idle":"2023-05-04T17:00:25.212466Z","shell.execute_reply":"2023-05-04T17:00:25.211563Z","shell.execute_reply.started":"2023-05-04T17:00:25.196902Z"},"trusted":true},"outputs":[],"source":["def evaluateQueries(descrpitors,classes_df,classes_count,name,n,percent,partition=False,sim_function=cosine_similarity):\n","    evaluation = {}\n","    dataset_path = \"\"\n","    multi_decoy = True\n","\n","    if name in datasets_dict.keys():\n","        if partition:\n","            if \"partition\" in datasets_dict[name].keys():\n","                if partition in datasets_dict[name][\"partition\"]:\n","                    dataset_path = \"./Datasets/\"+name+\"/\"+partition\n","                else: \n","                    print(\"Partition doesn't exist\")    \n","            else:\n","                print(\"This dataset doesn't have a partition\")\n","\n","        else:\n","            if \"partition\" in datasets_dict[name].keys():\n","                print(datasets_dict[name][\"partition\"])\n","                print(\"Enter the partition name\")\n","            else:\n","                dataset_path = \"./Datasets/\"+name\n","\n","        with open(dataset_path+\"/ActivityDecoyClass.txt\", 'r') as f:\n","            if(int(f.readline())== 1):\n","                multi_decoy = False\n","        \n","        if dataset_path != \"\":\n","            with open(dataset_path+\"/Queries.txt\", 'r') as file:\n","                clss = 0\n","                for line in file:\n","                    classQueries = line.split()[:n]\n","                    evaluation_querie = {}\n","                    \n","                    if multi_decoy:\n","                        decoy_clss = clss*(-1)-1\n","                        classes_df_tmp = classes_df.loc[classes_df[\"class\"].isin([clss,decoy_clss])].copy()\n","                    else:\n","                        decoy_clss = -1\n","                        classes_df_tmp = classes_df.copy()\n","\n","                    \n","                    \n","                    for q in classQueries:\n","                        querie = descrpitors[int(q)-1]\n","                        tmp_df = classes_df_tmp.loc[classes_df_tmp[\"id\"]!=int(q)-1].copy()\n","\n","#                         tmp_df[\"similarity\"] = [cosine_similarity(descrpitors[i] ,querie) for i in tmp_df[\"id\"]]\n","                        tmp_df[\"similarity\"] = [sim_function(descrpitors[i] ,querie) for i in tmp_df[\"id\"]]\n","\n","                        tmp_df = tmp_df.sort_values(by='similarity',ascending=False)\n","                        \n","                        evaluation_pressesions = {}\n","                        print(q)\n","                        for p in percent:\n","                            num_rows = int(p * len(tmp_df))\n","                            subset_df = tmp_df.head(num_rows)\n","                            evaluation_pressesions[p] = list(subset_df[\"class\"]).count(clss)/(min(classes_count[clss]-1,len(subset_df)))\n","                        \n","                        evaluation_querie[q] = evaluation_pressesions\n","                    evaluation[clss] = evaluation_querie\n","                    clss+=1\n","    else:\n","        print(\"Dataset doesn't existe\")\n","\n","    return evaluation"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2023-05-04T17:00:25.214497Z","iopub.status.busy":"2023-05-04T17:00:25.213854Z","iopub.status.idle":"2023-05-04T17:00:25.224167Z","shell.execute_reply":"2023-05-04T17:00:25.223251Z","shell.execute_reply.started":"2023-05-04T17:00:25.214456Z"},"trusted":true},"outputs":[],"source":["def evaluationMeanDF(eval):\n","    evaluation = {}\n","    for key in eval.keys():\n","        df_tmp = pd.DataFrame(eval[key]).T\n","        evaluation[key] = dict(df_tmp.mean())\n","    df_eval = pd.DataFrame(evaluation).T\n","    df_eval.loc[\"mean\"] = df_eval.mean()\n","    return df_eval.round(3)"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-05-04T17:00:25.234885Z","iopub.status.busy":"2023-05-04T17:00:25.234250Z","iopub.status.idle":"2023-05-04T17:00:29.977944Z","shell.execute_reply":"2023-05-04T17:00:29.976805Z","shell.execute_reply.started":"2023-05-04T17:00:25.234850Z"},"trusted":true},"outputs":[],"source":["model_path = \"INSER_STABLEBASELINES_MODEL_NAME\"\n","agent = PPO.load(model_path)\n","dev = th.device('cuda:0' if th.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2023-05-04T17:00:29.980304Z","iopub.status.busy":"2023-05-04T17:00:29.979554Z","iopub.status.idle":"2023-05-04T17:00:29.988387Z","shell.execute_reply":"2023-05-04T17:00:29.987249Z","shell.execute_reply.started":"2023-05-04T17:00:29.980265Z"},"trusted":true},"outputs":[],"source":["\n","INPUT_SHAPE = (1,1024)\n","mlp_extr = agent.policy.mlp_extractor.policy_net\n","features_extr = agent.policy.features_extractor\n","def creatDescriptorArrayRL_PPO(fp):\n","    fp = np.array(fp)\n","    fp = fp.reshape(INPUT_SHAPE)\n","    fp = th.tensor(fp).float().unsqueeze(0)\n","    fp = fp.to(dev)\n","    \n","    fp = features_extr(fp).cpu().detach().numpy()\n","    return fp.reshape((INPUT_SHAPE[1],))\n","    # return fp"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2023-05-04T17:00:29.991712Z","iopub.status.busy":"2023-05-04T17:00:29.990155Z","iopub.status.idle":"2023-05-04T17:00:30.003255Z","shell.execute_reply":"2023-05-04T17:00:30.001890Z","shell.execute_reply.started":"2023-05-04T17:00:29.991674Z"},"trusted":true},"outputs":[],"source":["import json\n","def save_eval_as_json(eval_rl:type(dict),name:str):\n","    if len(name) < 1:\n","        print(\"name must be set\")\n","        return\n","    with open(name+\".json\",mode=\"w\") as jf:\n","        jf.write(json.dumps(eval_rl,ensure_ascii=False))\n","    \n","t = {\"ds1\":{\"1\":{\"0.1\":[0,0.9,0.2,0.8]}}}\n","save_eval_as_json(t,\"test\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-04T17:00:30.013927Z","iopub.status.busy":"2023-05-04T17:00:30.013130Z","iopub.status.idle":"2023-05-04T17:17:06.245688Z","shell.execute_reply":"2023-05-04T17:17:06.244516Z","shell.execute_reply.started":"2023-05-04T17:00:30.013887Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["fp = \"ECFP4\"\n","simil = \"Jaccard\"\n","queries_n = 10\n","p = [0.01,0.05]\n","for key,value in datasets_dict.items():\n","    dataset = key\n","    print(\"-\"*14)\n","    print(\"Dataset : \",dataset)\n","    if \"partition\" in value.keys():\n","        for partition in value[\"partition\"]:\n","            print(\"-\"*14)\n","            print(f\"Dataset : {dataset} -> partition : {partition}\")\n","            descrpitors_fp,classes_df,classes_count = loadDataset(dataset,fp,partition)\n","            eval_fp = evaluateQueries(descrpitors_fp,classes_df,classes_count,dataset,queries_n,p,partition)\n","            df_eval_fp = evaluationMeanDF(eval_fp)\n","            df_eval_fp.to_csv(\"./Evaluation/\"+dataset+\"/\"+partition+\"/evaluation_\"+fp+\"_fp_\"+dataset+\"_\"+partition+\"_\"+simil+\".csv\")\n","\n","            descrpitors_rl = np.apply_along_axis(creatDescriptorArrayRL_PPO, axis=1, arr=descrpitors_fp)\n","            eval_rl = evaluateQueries(descrpitors_rl,classes_df,classes_count,dataset,queries_n,p,partition,sim_function=jaccard_similarity)\n","            save_eval_as_json(eval_rl,f\"{dataset}_{partition}_eval_cnn_mha\")\n","            df_eval_rl = evaluationMeanDF(eval_rl)\n","            df_eval_rl.to_csv(\"./Evaluation/\"+dataset+\"/\"+partition+\"/evaluation_\"+fp+\"_rl_cnn_mha_\"+dataset+\"_\"+partition+\"_\"+simil+\".csv\")\n","    else:\n","        descrpitors_fp,classes_df,classes_count = loadDataset(dataset,fp)\n","        eval_fp = evaluateQueries(descrpitors_fp,classes_df,classes_count,dataset,queries_n,p)\n","        df_eval_fp = evaluationMeanDF(eval_fp)\n","        df_eval_fp.to_csv(\"./Evaluation/\"+dataset+\"/evaluation_\"+fp+\"_fp_\"+dataset+\"_\"+simil+\".csv\")\n","\n","        descrpitors_rl = np.apply_along_axis(creatDescriptorArrayRL_PPO, axis=1, arr=descrpitors_fp)\n","        eval_rl = evaluateQueries(descrpitors_rl,classes_df,classes_count,dataset,queries_n,p)\n","        df_eval_rl = evaluationMeanDF(eval_rl)\n","        df_eval_rl.to_csv(\"./Evaluation/\"+dataset+\"/evaluation_\"+fp+\"_rl_\"+dataset+\"_\"+simil+\".csv\")\n","    "]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
